# Slack Credentials (REQUIRED)
# Get these from your Slack app configuration at https://api.slack.com/apps
SLACK_BOT_TOKEN=xoxb-your-bot-token        # Bot User OAuth Token from OAuth & Permissions
SLACK_SIGNING_SECRET=your-signing-secret   # Signing Secret from Basic Information

# Anthropic API Configuration (RECOMMENDED - primary LLM provider)
# Get your API key from https://console.anthropic.com/
# Provides direct access to Claude models with prompt caching support for 90% cost reduction
# When set, this takes priority over AI Gateway and OpenAI
ANTHROPIC_API_KEY=your-anthropic-api-key

# Anthropic Model Configuration (OPTIONAL)
# Supported models: claude-sonnet-4-5 (default), claude-sonnet-4, claude-opus-4, claude-haiku-4-5
# Default: claude-sonnet-4-5 (best balance of quality and cost with caching)
# ANTHROPIC_MODEL=claude-sonnet-4-5

# OpenAI Credentials (OPTIONAL - fallback provider)
# Get this from your OpenAI account at https://platform.openai.com/api-keys
# Used as fallback when Anthropic and AI Gateway are not configured
# Also used for embeddings in Azure Search vector search
OPENAI_API_KEY=your-openai-api-key
# OPENAI_FALLBACK_MODEL=gpt-4o-mini  # Fallback model when OpenAI is used

# Exa Search Configuration (REQUIRED for web search functionality)
# Get your API key from https://exa.ai
EXA_API_KEY=your-exa-api-key

# Database Configuration (OPTIONAL - for context persistence and KB workflow state)
# Without DATABASE_URL, the bot runs in memory-only mode (all data lost on restart)
# Create a free database at https://neon.tech
# After creating, run: npm run db:migrate
# Example format: postgresql://user:password@host.neon.tech/dbname?sslmode=require
DATABASE_URL=postgresql://user:password@host.neon.tech/dbname?sslmode=require

# ServiceNow Configuration (OPTIONAL - enables case/incident lookup tools)
# Get these from your ServiceNow instance administrator
SERVICENOW_INSTANCE_URL=https://your-instance.service-now.com

# ServiceNow Authentication: Use EITHER username/password OR API token
SERVICENOW_USERNAME=your-servicenow-username
SERVICENOW_PASSWORD=your-servicenow-password
# OR use API token instead:
# SERVICENOW_API_TOKEN=your-servicenow-api-token

# ServiceNow Table Configuration (OPTIONAL overrides)
# Defaults shown below - only set if your instance uses different table names
# SERVICENOW_CASE_TABLE=sn_customerservice_case
# SERVICENOW_CASE_JOURNAL_NAME=x_mobit_serv_case_service_case

# Azure AI Search Configuration (OPTIONAL - enables similar case search with MSP attribution)
# Get these from your Azure AI Search service in Azure Portal
# This enables cross-client similar case search with proper client attribution
# The production index uses BM25 keyword search (no embeddings required)
AZURE_SEARCH_ENDPOINT=https://your-search-service.search.windows.net
AZURE_SEARCH_KEY=your-azure-search-api-key
AZURE_SEARCH_INDEX_NAME=case-intelligence-prod

# Embedding model for KB article vector search (OPTIONAL - only needed for KB article similarity)
# Default: text-embedding-3-small
# CASE_EMBEDDING_MODEL=text-embedding-3-small

# Relay Gateway Configuration (REQUIRED for /api/relay endpoint)
# This is a shared HMAC secret for authenticating external agents/services
# Generate a strong random secret: openssl rand -base64 32
# All upstream services must use this same secret to sign their requests
RELAY_WEBHOOK_SECRET=your-shared-secret-key

# Business Context Configuration (OPTIONAL - enhances LLM responses with customer knowledge)
# When enabled, the bot enriches prompts with information about clients, vendors, and platforms
# Edit business-contexts.json and run: npm run db:import-contexts
# Default: true (feature is enabled)
# ENABLE_BUSINESS_CONTEXT=true

# Knowledge Workflow Tuning (OPTIONAL)
# Timeout window (hours) before gathering is abandoned
KB_GATHERING_TIMEOUT_HOURS=24
# Maximum clarification attempts before abandonment
KB_GATHERING_MAX_ATTEMPTS=5

# Intelligent Assistant Tuning (OPTIONAL)
# Minimum problem description length required for similar-case search
ASSISTANT_MIN_DESCRIPTION_LENGTH=10
# Number of similar cases to retrieve when suggesting guidance
ASSISTANT_SIMILAR_CASES_TOP_K=3
# Only provide intelligent assistance for cases in these states (comma-separated)
# Default: New,In Progress,On Hold,Pending,Awaiting Info,Work in Progress
# Excludes: Closed, Resolved, Cancelled (no value in providing guidance for closed cases)
# ASSISTANT_ACTIVE_STATES=New,In Progress,On Hold,Pending,Awaiting Info

# Knowledge Base Similarity Search (OPTIONAL)
# Number of existing KB articles to compare before drafting new content
KB_SIMILAR_CASES_TOP_K=3

# AI Gateway Configuration (LEGACY - deprecated in favor of direct Anthropic API)
# Get your API key from Vercel AI Gateway or your gateway provider
# NOTE: AI Gateway does NOT support prompt caching - migrate to direct Anthropic API for cost savings
# Only used when ANTHROPIC_API_KEY is not set (backwards compatibility)
# Default model: anthropic/claude-sonnet-4.5
# AI_GATEWAY_API_KEY=your-gateway-api-key
# AI_GATEWAY_DEFAULT_MODEL=anthropic/claude-sonnet-4.5  # Override default model

# Case Classification Configuration (OPTIONAL - enables AI-powered case triage)
# Feature flag to enable/disable case classification
# ENABLE_CASE_CLASSIFICATION=false

# Classification behavior settings
# CASE_CLASSIFICATION_WRITE_NOTES=false  # Whether to write work notes back to ServiceNow
# CASE_CLASSIFICATION_RECORDS=sn_customerservice_case  # Table to classify
# CASE_CLASSIFICATION_MAX_RETRIES=1  # Max retry attempts for failed classifications

# ServiceNow webhook security
# SERVICENOW_WEBHOOK_SECRET=your-webhook-secret  # HMAC secret for webhook validation

# Workflow routing configuration (JSON string)
# CASE_WORKFLOW_ROUTING={"assignment_group": {"sys_id": "workflow_id"}}
# Example: {"Network Support": {"sys_id": "network_workflow_id"}, "Application Support": {"sys_id": "app_workflow_id"}}

# Workflow prompt overrides (JSON string)
# CASE_WORKFLOW_PROMPTS={"workflow_id": "custom prompt text"}
# Use to provide specific instructions for different workflow types

# Quick triage settings
# CASE_QUICK_TRIAGE=true  # Enable quick triage mode for faster processing
# CASE_BUSINESS_CONTEXT_ENABLED=true  # Include business context in classification

# Business Context Admin API (OPTIONAL - for production admin interface access)
# Generate a strong random token: openssl rand -base64 32
# If not set, admin API is only accessible in development mode (vercel dev)
# BUSINESS_CONTEXT_ADMIN_TOKEN=your-admin-token-here

# LangSmith Tracing Configuration (OPTIONAL - for LLM observability and debugging)
# Get your API key from https://smith.langchain.com/
# Provides detailed tracing of LLM calls, token usage, prompts/completions, and chain execution
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_PROJECT=ai-sdk-slackbot
# LANGSMITH_ENDPOINT=https://api.smith.langchain.com  # Optional: custom endpoint
# LANGSMITH_TAGS=production,slack  # Optional: comma-separated tags for filtering traces
# LANGSMITH_SAMPLE_RATE=1.0  # Optional: sample rate (0.0-1.0), default 1.0 (100%)

# Feature Flags (OPTIONAL - for gradual rollout of refactored code)
# These flags control which implementation is used for core orchestration flows
# REFACTOR_ENABLED=false           # Enable refactored agent orchestrator (generate-response.ts)
# REFACTOR_PASSIVE_ENABLED=false   # Enable refactored passive flow (handle-passive-messages.ts)
